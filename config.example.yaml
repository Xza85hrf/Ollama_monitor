base_url: "http://host.docker.internal:11434"
timeout: 30
endpoints:
  "/":
    path: "/"
    method: "GET"
    expected_status: 200
    expected_content: "Ollama is running"
  "/api/generate":
    path: "/api/generate"
    method: "POST"
    expected_status: 200
    headers:
      Content-Type: "application/json"
    body: {"model":"your-config-model", "prompt": "Provide a summary of AI", "format": "json", "stream": false}

